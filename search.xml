<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[学习方法——费曼技巧]]></title>
      <url>%2F2020%2F01%2F31%2F%E8%B4%B9%E6%9B%BC%E6%8A%80%E5%B7%A7%2F</url>
      <content type="text"><![CDATA[费曼技巧是一种简单有效的学习方法，简单来说就是假装把你要学习的概念教授给别人，如果不能讲清楚就重新学习。它有四个步骤： 选择一个你要学习的概念 假装要把它教给别人 如果发有解释不清的地方，就重新学习 尝试简化你的教授过程 两种知识有两种知识，一种是知其名，另一种是知其意。如果“只知其名不知其意”是不可能给别人讲述清楚的。 说他知道自己的想法但却无法表达的人, 通常并不知道他自己的想法。 – Mortimer Adler 费曼技巧第一步：把它教给孩子取出一张白纸，在顶部写下你想要学习的主题(subject)。写出你对这个主题的理解，就像你正在把它教给孩子一样。注意你的受教对象，不是那些聪明的成年人，而是一个8岁的孩子，他有足够的词汇和注意力来理解这些基本概念和概念间的关系。 许多人倾向于使用复杂的词汇和行话来掩盖他们并不理解的东西。但我们只是在欺骗自己，因为我们不知道自己不理解。此外，使用行话也掩盖了我们周围人的误解。 当你使用简单的话语从头到尾写出一个孩子可以理解的想法，你会强迫自己在更深的层次上理解这个概念，并简化想法之间的联系。如果你讲述不清，你便清楚知道了你距离理解它还存在的差距(gaps)，这是件好事，它预示着学习的机会。 第二步：Review在第一步中，你难免会遇到讲述不清的地方，你可能是因为忘记了或者是因为没有深刻理解某些概念。 这些都是非常宝贵的反馈，因为你已经发现了你需要再学习的地方。这时候你需要重新学习，直到你可以清晰的阐述它。 提前知道哪里掌握的不好也可以让你在运用知识时少犯错误。 第三步：组织和简化现在你已经一份刚写好的笔记，重新组织、简化它。 大声读出来。如果解释得不够简单或者听起来仍然令人困惑，这说明你需要再接再厉。 第四步（可选）：传递它如果你真的想确定自己是否理解，那就跑去把它教给某个人（理想情况下，谁对这个主题知之甚少，谁就是理想听众，或者找个8岁的孩子！）。对你的知识的最终考验是你将它传达给其他人的能力。 感悟 学习的精髓不是“要知道”（只知其名）而是“要理解”（知其意）。 如果说不清就是没有深刻的理解，越能简单的阐述理解的也就越深刻。 那么面试、评审、分享等也是这个道理，如果能通俗易懂的表述，就说明有足够深刻的理解。 写博客是一个很好的学习过程。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记一次计算密集型服务的性能优化]]></title>
      <url>%2F2020%2F01%2F13%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E6%9C%8D%E5%8A%A1%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
      <content type="text"><![CDATA[性能优化是一个庞杂的话题，不同的场景，不同的视角都会得到不同的理解。比如：有的为了提高吞吐，有的为了降低延迟，有的为了节省资源。他们并不是同一个问题，有时可以牺牲一定的延迟来换取更高的吞吐，比如批量处理；有时可以用更多的存储空间来换取更低的延迟，比如哈希表…… 本文讲述的是对计算密集型服务提高吞吐和降低延迟的优化经验和理解。 一、背景这是微服务框架下的一个末端计算节点，使用C++编写，只有一个上游调用方，没有下游。不使用数据库等外部存储，所有数据都在内存中（约占用45GB内存）。使用Thrift ThreadPool框架，接收到请求后，根据内存中的数据做“简单”计算后打成ProtoBuffer包返回给调用方。 在48核物理机上，优化前极限QPS是3.5k左右，优化后的极限QPS超过14k，性能提升4倍。 二、方法论性能优化也可以从不同层面去考虑，比如业务流程、架构设计、硬件配置亦或是代码编写等。本文主要从代码优化的角度来优化性能。 使用perf等工具可以分析出热点代码。根据二八法则，优化20%的代码可以提升80%的性能。所以要先找出瓶颈，然后优化这个瓶颈，然后再找下一个瓶颈…… 如上图，我归纳了一些常见的性能瓶颈。一般极限QPS下如果CPU利用率不高，就要考虑是否有阻塞或者竞争（锁）；如果CPU利用率达到或者接近100%，极限性能还是不高，可以考虑优化流程，算法，去除不必要的内存拷贝，减少堆内存的申请、释放和系统调用等。 当然，有些系统看上去没有明显的瓶颈（没有明显的热点代码），这时候就比较考验工程师对性能优化的理解了。一般可以从精简流程或者使用高效的“方法”替代低效的“方法”入手。比如减少临时对象，使用哈希表替代红黑树，提高缓存利用率等方法。 做好性能优化的关键是：了解计算机是如何运转的。 了解硬件的工作原理，知道哪些操作快哪些些操作慢，比如：相比于内存，磁盘IO的速度比较慢；相比于cache，内存的读写比较慢等等。 在硬件之上要了解操作系统的工作原理，比如：堆内存和栈内存的区别，系统调用和函数调用的区别，锁的实现原理等等。 在操作系统之上要了解编译器和标准库都做了什么。执行一行看似简单的代码计算机要做哪些操作? 再之上就是对算法和业务的理解了。很多时候低效的算法和冗余的业务逻辑才是拖累系统性能的关键。 性能优化是一个系统工程，不能一味的追求性能，除了如何优化还要考虑其他问题： 是否需要优化？过早的优化是万恶之源。 投入产出比 稳定性，因改造引入的风险 鲁棒性 代码的可读性 维护成本 可扩展性 三、第一轮优化——去除IO阻塞找到瓶颈，依据数据而不是凭空猜测。 优化前的极限QPS是3.5k，简单分析一下发现总的CPU利用率只有50%左右，推断系统内部有严重的阻塞（条件等待）。常见阻塞原因有IO阻塞和互斥锁，使用iostat进一步观察系统状态发现await和iowait都很高，这说明IO阻塞比较严重。因为系统运行时只有写日志会触发IO，所以怀疑是写同步日志造成的IO阻塞。关闭日志后压测发现极限QPS可以达到8k+，这基本可以断定写同步日志对系统性能影响比较大。将同步日志改为异步日志很容易，可是也会带来一些弊端。最严重的就是有丢日志的风险，进程异常退出时可能导致缓存中的日志不能刷到磁盘上。考虑到日志本身价值不大，只有在系统异常退出时（比如OOM），需要日志辅助定位问题。综合考虑后，打算把错误日志记同步日志，其他的记异步日志。这次优化的收益很明显，只修改了日志配置，极限QPS从3.5k提升到7k+。后续打算把访问日志分离出来，也记同步日志，降低丢日志的影响。 四、第二轮优化——代码优化二八法则，优先解决头部问题。 火焰图 从火焰图上看到除了malloc和free没有明显的热点代码。压到极限QPS时，总的CPU利用率也只有70%。分析一下malloc的过程，不难发现其内部是有线程锁的。IO阻塞解决后，malloc的阻塞问题就凸显出来了。TCMalloc做了线程级的缓存，理论上可以缓解锁竞争的问题。可是换用TCMalloc后发现性能并没有提升（后来证明是因为未正确编译导致的，这里走了一些弯路），然后就尝试了其他思路，从代码的层面入手。 要了解计算机是如何运行的，知道每行代码都做了什么。 4.1 去除冗余逻辑由于历史原因，代码中有一些中间数据结构，数据结构间的转换带来了额外的性能开销。还有一些为记录调试日志的额外操作，比如吧PB序列化成文本或者字符串拼接等。再有就是去除不必要的拷贝和临时变量。 4.2 标准模板(STL)的性能优化在代码中没有搜索到太多的malloc/free和new/delete，这和火焰图显示的结果不符。 进一步翻阅代码发现有大量的STL容器（vector、string等）的使用，虽然这些都是在栈上创建的对象，但是他们都会申请堆上的内存。这些容器在增长的时候都可能会重新申请内存，比如vector的push_back()就会因为剩余容量不足导致重新申请内存，而且还可能要触发拷贝。字符串（string）拼接的时候也有类似的问题。这种问题可以同reserve来解决，前提是能预估最大容量。 另外vector的push_back()会多触发一次拷贝，所以用emplace_back()性能会更好一些。 针对调用频繁，size不大的且可以确定的vector，用完全在栈上的对象（我用STL风格的API封装的“数组”）代替。栈内存的申请几乎不消耗时间，只需要移动栈顶指针即可，内存连续，cache利用率也高;而堆内存的申请就比较复杂，可能涉及到线程间的竞争，即使有线程级缓存，也难免会带来额外的计算开销。 iostream用起来很方便，但是性能很糟糕，调用频繁的地方可以用snprintf()代替。 如果可以的话，用unordered_map代替map，用数组代替unordered_map。 五、第三轮优化——减少竞争做完第二轮优化，性能提升50%，极限QPS从7k提升到10k+。这时候malloc/free带来的开销就更加突出，而且极限情况下CPU利用率也只有70%。所以锁推断是因为malloc/free中有线程锁，加上STL频繁的申请释放内存导致的。因为TCMalloc有线程级的缓存，可以缓解这一现象，这和第二轮优化中的测试结果不符（因为编译问题导致TCMalloc未能生效）。仔细检查并修正后，性能大幅提升，极限QPS可以超过14k。CPU利用率达到95%左右。 优化后的火焰图 六、还可以做哪些优化前三轮优化使性能提升4倍，总体改动量不大，风险也可控，所以产出投入比还是很高的。还有一些可以优化的点，因为改造成本、改造风险、运维成本和收益不够等原因暂时没有实施。 6.1 优化数据结构服务会用到大量的静态数据，单份数据超过20GB。这些数据的结构还有优化空间。 有些数据用二叉树做索引，如果换成哈希表性能会更好。 数据不够紧凑，还有压缩空间，一般数据越紧凑对cache的利用率也会越高。 6.2 优化ProtoBufferProtoBuffer也会因为频繁的申请/释放小对象导致性能不佳，可以用Arena Allocation优化。 Memory allocation and deallocation constitutes a significant fraction of CPU time spent in protocol buffers code. By default, protocol buffers performs heap allocations for each message object, each of its subobjects, and several field types, such as strings. These allocations occur in bulk when parsing a message and when building new messages in memory, and associated deallocations happen when messages and their subobject trees are freed. 6.3 使用Huge PageHuge Page，是指的大页内存管理方式。与传统的4KB的普通页管理方式相比，Huge Page管理大内存(8GB以上)更为高效。我们的服务占用40GB以上的内存，所以理论上使用Huge Page会有一定性能提升。不过使用Huge Page也会带来额外的运维成本，也需要综合考虑风险和稳定性等原因。 Huge Page的示意图 七、总结7.1 是否需要优化？性能优化是一个复杂的问题，除了如何提高性能还需要从收益、成本、风险等维度综合考虑。尤其要考虑清楚为什么要优化？是否需要优化？产出投入比是否够高？是否有更好的解决方案? 7.2 “上兵伐谋”不能上来就扎到代码里，“宏观”上的优化可能会有奇效。 流程：业务流程是否可以优化？有时删掉一个冗余的逻辑会有大幅的收益。 算法：在规模较大时，时间复杂度上的差异往往是致命的。 机制：同步OR异步，通知OR轮询，阻塞OR非阻塞等等。机制上的差异是很难弥补的。 取舍：时间和空间互换，吞吐和延迟互换，做出合适的取舍，可以事半功倍。 7.3 “其下攻城”代码是给人看的，程序还要靠计算机来运行。要知道计算机是如何运行的，知道每行代码背后计算机都做了什么，知道哪些操作快、哪些操作慢，才能做好性能优化。 有太多的点不能一一列举，总结一下就是：理论指导实践，实践检验理论。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RCU(Read Copy Update)]]></title>
      <url>%2F2019%2F05%2F27%2Frcu%2F</url>
      <content type="text"><![CDATA[前段时间做系统重构，需要一个快速的本地缓存，类似于黑名单，读多写少的那种。之前一直用的是哈希表加读写锁的方案，如果出现大规模的写操作，会导致读操作被阻塞。想找一个更高效的解决方案，最好是无锁。 Linux kernel中的RCU以前听说过Radix Tree，Linux用它来管理路由表，和我面临的场景有些类似，相信Linux选用的肯定是高效的。所以打算研究一下，找一些启发。研究时发现使用的是Radix Tree + RCU来解决的。感觉推开了新世界的大门。 以链表为例，通过无锁操作可以无锁的更新链表，如图： 初始链表 申请新节点内存 复制要更新的节点 修改next指针 修改新节点中的内容 将其插入链表 以上所有操作都不需要加锁，但是有一个问题，何时可以释放p指向的节点？因为不确定是否还有其他“线程”在读这块内存。这好像是一个内存回收的问题，在带有GC的语音中，这似乎不是问题，但是c/c++中不行。 利用一些内存回收技术可以解决这一问题，比如智能指针或者QSBR(Quiescent State-Based Reclamation)。 智能指针智能指针是一个简单易行的方案，但是智能指针的赋值不是原子的，需要对其加锁。 QSBRQSBR的核心思想就是识别出线程的不活动(quiescent)状态，那么什么时候才算是不活动的状态呢？这个状态和临界区状态是相对的，线程离开临界区就是不活动的状态了。 简单的说就是每个读线程在离开临界区时记录一下自己的状态，写线程检查这个状态，当所有线程都离开临界区时就可以释放旧节点了。 在服务中使用RCU-QSBR幸好有urcu这个开源实现。如前文所说，数据可以通过copy的方式进行原子更新，难点在于合适释放被替换的节点。利用RCU-QSBR我们可以在服务线程返回请求时标记自己退出临界区。这样做虽然扩大了临界区的范围，但是对应用层是透明的，应用层的开发者感知不到RCU的存在。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[多读场景下的本地缓存]]></title>
      <url>%2F2019%2F04%2F25%2Frcu-cache%2F</url>
      <content type="text"><![CDATA[在读写分离的架构中通常需要一个高性能的缓存，而且这个缓存是读多写少的。比如黑名单缓存，一个线程负责更新，多个线程读取。 哈希表 + 读写锁这是一个简单通用的方案，一般对性能要求不高时可以使用。虽然简单，缺点也很明显，写时会阻塞读。 Concurrent Hash Map支持多线程的哈希表有很多种实现方式，Java中的ConcurrentHashMap是一个不错的实现，但其本质也是分段加锁，虽然降低了竞争锁的概率，但是也不能避免。 多线程下，哈希表的rehash是一个难题，大多实现都很难避免加锁，而且C++也没有相应的标准。 双Buffer双Buffer也是一个常用的手段。一般有两种：一种是两块固定的不会被回收的Buffer，两个Buffer交替使用，这样做可以避免Buffer的内存回收，但是需要管理两个buffer的交替时机，这是一个难题。很多时候是靠“超时”来保证的，比如双buffer的交替频率是10秒，而buffer的一次访问时间不会超过100毫秒等。这种方式虽然hack，但大部分场景下是有效的。 COW + 智能指针 + 自旋锁(spin lock)用智能指针管理内存是个不错的方式，但是也有弊端。智能指针的赋值不是原子的，所以多线程情况下其赋值时需要加锁（C++11中有智能指针的原子操作），为了保证效率可以选用spin lock。除了需要加锁还有另外一个问题：“不能确定内存的释放时机”，智能指针是在引用计数归零时释放内存的，考虑到业务系统复杂多变，而且在多线程情况会变得更复杂。如果在处理业务的线程释放，可能会影响其响应时间。而且如果更新的频率过高而且旧的内存迟迟不能释放，会导致过多的内存副本，严重时会导致OOM。 RCU(Read Copy Update) + QSBRRCU并不是新技术其理论早有人提出，Linux内核中也有大量的使用。利用RCU可以做到读时无锁。不同于用智能指针管理内存，利用RCU和QSBR可以优雅的回收内存。写线程可以知道读线程何时结束读，确保及时、安全的回收内存。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[有趣的代码]]></title>
      <url>%2F2018%2F05%2F03%2F%E6%9C%89%E8%B6%A3%E7%9A%84%E4%BB%A3%E7%A0%81%2F</url>
      <content type="text"><![CDATA[今天刷论坛时发现下面这段代码1i = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck? 哈哈，刚看到这行时我也不禁说了一句：“what the fuck?” 完整的代码如下： 123456789101112131415161718192021222324/*** float q_rsqrt( float number )*/float Q_rsqrt( float number )&#123; long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = * ( long * ) &amp;y; // evil floating point bit level hacking i = 0x5f3759df - ( i &gt;&gt; 1 ); // what the fuck? y = * ( float * ) &amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration// y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed#ifndef Q3_VM#ifdef __linux__ assert( !isnan(y) ); // bk010122 - FPE?#endif#endif return y;&#125; 这是《雷神之锤III》中的代码(quake3-1.32b/code/game/q_math.c)。是平方根倒数速算法。把浮点数当做整数来处理，还有这种操作？（what the fuck?）不禁感叹前人的智慧。 联想到以前读Redis源码时，里面也有有趣的（diao diao的）注释。 12"don't play with this unless you benchmark! ... just believe me, it works"（不要优化这段代码，除非你做了性能测试。…… 相信我） 完整的代码在这里。 123456789101112131415161718192021222324252627#define HSIZE (1 &lt;&lt; (HLOG))/* * don't play with this unless you benchmark! * the data format is not dependent on the hash function. * the hash function might seem strange, just believe me, * it works ;) */#ifndef FRST# define FRST(p) (((p[0]) &lt;&lt; 8) | p[1])# define NEXT(v,p) (((v) &lt;&lt; 8) | p[2])# if ULTRA_FAST# define IDX(h) ((( h &gt;&gt; (3*8 - HLOG)) - h ) &amp; (HSIZE - 1))# elif VERY_FAST# define IDX(h) ((( h &gt;&gt; (3*8 - HLOG)) - h*5) &amp; (HSIZE - 1))# else# define IDX(h) ((((h ^ (h &lt;&lt; 5)) &gt;&gt; (3*8 - HLOG)) - h*5) &amp; (HSIZE - 1))# endif#endif/* * IDX works because it is very similar to a multiplicative hash, e.g. * ((h * 57321 &gt;&gt; (3*8 - HLOG)) &amp; (HSIZE - 1)) * the latter is also quite fast on newer CPUs, and compresses similarly. * * the next one is also quite good, albeit slow ;) * (int)(cos(h &amp; 0xffffff) * 1e6) */ 短短的几行代码，堪称智慧的结晶。这也是计算机有趣的地方。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用C++写一个单例]]></title>
      <url>%2F2018%2F04%2F28%2Fsingleton%2F</url>
      <content type="text"><![CDATA[“请用C++写一个单例，考虑一下多线程环境。”这是一个常见的面试题，别人问过我，我也问过别人。这个问题可以很简单，也可以很复杂。 简单有效的单例1234567class Singleton &#123;public: static Singleton* GetInstance() &#123; Singleton singleton; return &amp;singleton; &#125; &#125;; 在C++11中静态局部变量的初始化是线程安全的，参考链接。这种写法既简单，又是线程安全的，可以满足大多数场景的需求。 饿汉模式单例在程序初期进行初始化。即如论如何都会初始化。12345678910class Singleton &#123;public: static Singleton* GetInstance() &#123; return singleton; &#125; static Singleton* singleton;&#125;;Singleton* Singleton::singleton = new Singleton(); 这种写法也是线程安全的，不过Singleton的构造函数在main函数之前执行，有些场景下是不允许这么做的。改进一下：123456789101112class Singleton &#123;public: static Singleton* GetInstance() &#123; return singleton; &#125; int Init(); static Singleton* singleton;&#125;;Singleton* Singleton::singleton = new Singleton(); 将复杂的初始化操作放在Init函数中，在主线程中调用。 懒汉模式单例在首次调用时进行初始化。12345678910111213class Singleton &#123;public: static Singleton* GetInstance() &#123; if (singleton == NULL) &#123; singleton = new Singleton(); &#125; return singleton; &#125; static Singleton* singleton;&#125;;Singleton* Singleton::singleton = NULL; 这样写不是线程安全的。改进一下：123456789101112131415class Singleton &#123;public: static Singleton* GetInstance() &#123; lock(); if (singleton == NULL) &#123; singleton = new Singleton(); &#125; unlock(); return singleton; &#125; static Singleton* singleton;&#125;;Singleton* Singleton::singleton = NULL; 这样写虽是线程安全的，但每次都要加锁会影响性能。 DCLP（Double-Checked Locking Pattern）在懒汉模式的基础上再改进一下：1234567891011121314151617class Singleton &#123;public: static Singleton* GetInstance() &#123; if (singleton == NULL) &#123; lock(); if (singleton == NULL) &#123; singleton = new Singleton(); &#125; unlock(); &#125; return singleton; &#125; static Singleton* singleton;&#125;;Singleton* Singleton::singleton = NULL; 两次if判断避免了每次都要加锁。但是，这样仍是不安全的。因为”singleton = new Singleton();”这句不是原子的。这句可以分为3步： 申请内存 调用构造函数 将内存指针赋值给singleton 上面这个顺序是我们期望的，可以编译器并不会保证这个执行顺序。所以也有可能是按下面这个顺序执行的： 申请内存 将内存指针赋值给singleton 调用构造函数 这样就会导致其他线程可能获取到未构造好的单例指针。解决办法：12345678910111213141516171819class Singleton &#123;public: static Singleton* GetInstance() &#123; if (singleton == NULL) &#123; lock(); if (singleton == NULL) &#123; Singleton* tmp = new Singleton(); memory_barrier(); // 内存屏障 singleton = tmp; &#125; unlock(); &#125; return singleton; &#125; static Singleton* singleton;&#125;;Singleton* Singleton::singleton = NULL; 语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。简单的说就是保证指令一定程度上的按顺序执行，避免上述所说的乱序行为。把单例写成这么复杂也是醉了。 返回指针还是引用？Singleton返回的实例的生存期是由Singleton本身所决定的，而不是用户代码。我们知道，指针和引用在语法上的最大区别就是指针可以为NULL，并可以通过delete运算符删除指针所指的实例，而引用则不可以。由该语法区别引申出的语义区别之一就是这些实例的生存期意义：通过引用所返回的实例，生存期由非用户代码管理，而通过指针返回的实例，其可能在某个时间点没有被创建，或是可以被删除的。但是这两条Singleton都不满足，所以返回引用更好一些。 结论12345678910111213141516class Singleton &#123;public: static Singleton&amp; GetInstance() &#123; static Singleton singleton; return singleton; &#125; // 如果需要有比较重的初始化操作，则在安全的情况下初始化 int Init();private: // 禁用构造函数、拷贝构造函数、拷贝函数 Singleton(); Singleton(const Singleton&amp;); Singleton&amp; operator=(const Singleton&amp;);&#125;; 这种写法比较简单，可以满足大多数场景的需求。如果不能满足需求，再考虑DCLP那种复杂的模式。如《UNIX编程艺术》中所说：“Keep it sample, Stupid！” 参考The Singleton Pattern面试中的Singleton内存屏障]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[静态的希尔伯特RTree]]></title>
      <url>%2F2018%2F04%2F25%2Fhilbert-rtree%2F</url>
      <content type="text"><![CDATA[先考虑一个常见的问题：如何搜索附近的人（车、银行、餐厅等）？可以把这类问题抽象成：快速搜索二维（或者高维）空间上某一指定区域内的数据。很明显，简单的二叉树或者哈希表解决不了这个问题。 一、空间索引空间索引是对二维或者多维空间坐标的索引，其本质不外乎树和哈希表两种结构。比如GeoHash就是将空间划分成若干子空间，然后再映射成唯一的编码，以哈希表的形式存储。再比如KDTree和RTree，其本质都是树，不同的是KDTree是通过分割空间的方式构建树，而RTree是通过选取空间的方式构建树。 二、RTreeRTree是高度平衡的多叉树。他用最小外接矩形（minimum bounding rectangle, MBR）表示一个节点，N个子节点的最小外接矩形构成了他们的父节点，如果某一层只有一个节点，那么该节点就是根（root）节点。如下图：如上图，R8、R9、R10是叶子节点，它们的最小外接矩形构成了它们的父节点R3。R3、R4、R5的最小外接矩形又构成了它们的父节点R1。构建RTree的关键就是如何构建这些最小外接矩形，一般这些矩形的面积、周长越小越好。也就是说同一节点下的各子节点距离越近越好。 三、希尔伯特曲线希尔伯特曲线是一种填充曲线，可以线性地贯穿二维或者更高维度每个离散单元，并且仅仅穿过一次，并对每个离散单元进行线性排序和编码，该编码作为该单元的唯一标识。希尔伯特曲线可以将高维空间中的数据映射到一维空间。如下图所示：从上图可以看出，希尔伯特编码相近的点在平面上的位置也相近。当然，这一性质在数学上是有证明的，这里不做讨论。 四、希尔伯特RTree 利用希尔伯特曲线的性质，可以将RTree的各子节点进行编码、排序，如此往复就可以构建一棵希尔伯特RTree。 算法描述：步骤一：计算每一个数据矩形中心的希尔伯特值步骤二：按照希尔伯特值升序将数据矩形排序步骤三：// 构造结点（层L=1） while（有更多的矩形） 生成一个新的R树结点 将后续C个矩形分配到这个结点上步骤四：// 构造更高层（L+1）的结点 L = L + 1 如果L层中只有一个节点，那么该节点就是根节点，算法结束 否则，把该层节点按照生成时间升序排序，重复步骤三 数据结构：12345struct HilbertRTree &#123; std::vector&lt;Node&gt; nodes_; // 所有的非叶子节点，root节点在末尾 std::vector&lt;Rectangle&gt; leaves_; // 叶子节点的最小外接矩形，和leaf_ids_ 一一对应 std::vector&lt;int&gt; leaf_ids_; // 和leaves_ 一一对应&#125;; 五、总结这个希尔伯特RTree有如下特点： 只支持批量加载，不支持插入和删除。 各节点的空间利用率接近100%，节省内存。 内存是连续的，可以直接将内存镜像写入文件，序列化和反序列化的速度很快。 同一节点下的各子节点相邻，查询效率较高。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[C++ 捕获异常时的栈信息]]></title>
      <url>%2F2017%2F12%2F12%2FC-%E6%8D%95%E8%8E%B7%E5%BC%82%E5%B8%B8%E6%97%B6%E7%9A%84%E6%A0%88%E4%BF%A1%E6%81%AF%2F</url>
      <content type="text"><![CDATA[由于种种原因，我还是不太推荐在C++使用异常机制。所以也不捕获异常，如果有问题直接让它挂掉。最近遇到一个问题，我的框架“帮”我捕获了vector抛出的越界异常，没有了core文件，很难定位问题具体出在哪一行。backtrace 是可以捕获的栈信息的，但是捕获到异常时已经丢失栈信息了。__cxa_throw 是在抛出异常时被调用的函数，在这个函数中可以捕获栈信息。 示例代码如下： 1234567extern "C" &#123; void __cxa_throw(void *ex, void *info, void (*dest)(void *)) &#123; last_size = backtrace(last_frames, sizeof last_frames/sizeof(void*)); static void (*const rethrow)(void*,void*,void(*)(void*)) __attribute__ ((noreturn)) = (void (*)(void*,void*,void(*)(void*)))dlsym(RTLD_NEXT, "__cxa_throw"); rethrow(ex,info,dest);&#125; 这段代码比较有趣，先是重载了__cxa_throw这个函数，然后又通过dlsym找到原函数。这种做法虽然不是很好，但对于我这种不使用异常的人很合适。 完整的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;dlfcn.h&gt;#include &lt;execinfo.h&gt;#include &lt;typeinfo&gt;#include &lt;string&gt;#include &lt;memory&gt;#include &lt;cxxabi.h&gt;#include &lt;cstdlib&gt;namespace &#123; void * last_frames[100]; size_t last_size; std::string exception_name; std::string demangle(const char *name) &#123; int status; std::unique_ptr&lt;char,void(*)(void*)&gt; realname(abi::__cxa_demangle(name, 0, 0, &amp;status), &amp;std::free); return status ? "failed" : &amp;*realname; &#125;&#125;extern "C" &#123; void __cxa_throw(void *ex, void *info, void (*dest)(void *)) &#123; exception_name = demangle(reinterpret_cast&lt;const std::type_info*&gt;(info)-&gt;name()); last_size = backtrace(last_frames, sizeof last_frames/sizeof(void*)); static void (*const rethrow)(void*,void*,void(*)(void*)) __attribute__ ((noreturn)) = (void (*)(void*,void*,void(*)(void*)))dlsym(RTLD_NEXT, "__cxa_throw"); rethrow(ex,info,dest); &#125;&#125;void foo() &#123; throw 0;&#125;int main() &#123; try &#123; foo(); &#125; catch (...) &#123; std::cerr &lt;&lt; "Caught a: " &lt;&lt; exception_name &lt;&lt; std::endl; // print to stderr backtrace_symbols_fd(last_frames, last_size, 2); &#125;&#125; 编译、执行后会输出：123456789g++ -std=c++0x -g -rdynamic -ldl test.cpp./a.outCaught a: int./a.out(__cxa_throw+0x82)[0x401e8a]./a.out(main+0x0)[0x401f18]./a.out(main+0xc)[0x401f24]/lib64/libc.so.6(__libc_start_main+0xfd)[0x3b6641ed5d]./a.out[0x401c69] 然后使用 addr2line 命令可以定位到代码中的位置。123addr2line 0x401f24 -e ./a.out./test.cpp:38]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用shadowsocks + vps科学上网]]></title>
      <url>%2F2017%2F08%2F11%2Fshadowsocks%2F</url>
      <content type="text"><![CDATA[由于众所周知的原因，出现了“科学上网”这门技术。由于VPN、ssh等在建立连接或通信是存在明显的特征，容易被针对，而且不是为“墙”而生的，在使用上多少有些蹩脚。所以shadowsocks应运而生。 shadowsocks存在以下优点： 通信时没有握手阶段，不容易被针对。 使用“智能代理”的方式，避免影响国内网站的访问。 支持iOS、安卓、Windows、macOS、OpenWRT等各种平台。 使用方便，一劳永逸。 购买VPS现在市面上的VPS提供商有好多，推荐使用老牌、稳定的Linode，每月5$。 点击链接，创建账户，充值后就可以使用了。支持信用卡和PayPal。 搭建shadowsocks服务网上可搜到很多如何搭建shadowsocks服务的博文，这里就不赘述了。不过有几点需要提醒的： shadowsocks有多用户的配置方法。一台VPS只给自己翻墙用太浪费了，可以分享给身边的朋友。这时多用户的优势就体现出来了！ 为了安全，配置防火墙还是必要的。屏蔽所有端口，使用白名单的方式开放需要的端口。 禁止root用户通过ssh登录。 修改ssh的端口，默认是22。 用supervisor启动shadowsocks还是不错的。注意配置“user=nobody”。 有kcptun、BBR等用来加速的黑科技可以选择。 配置客户端这个网上也有很多，不赘述了。同样有几点建议： 可以设置开机自启动。 可以自定义代理规则。 参考资料https://github.com/shadowsocks/shadowsocks/wiki]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用共享内存加速加载静态数据]]></title>
      <url>%2F2017%2F08%2F11%2Fmmap-load-data%2F</url>
      <content type="text"><![CDATA[之前遇见一个问题，程序启动时要加载大量的静态数据，导致启动速度很慢。这带来了两个弊端： 线上服务的重启成本太高，发布更新时服务不可用的时间较长。 增加开发调试的成本。 将需要加载的数据放在tmpfs中，程序启动时用mmap挂载内存，可以达到“零”秒启动的效果。 如果是map、unordered_map等比较复杂的数据结构，则需要重新组织一下。比如：map可以用二分查找代替，unordered_map也可以映射到线性地址空间上。 关于运行效率，由于是静态数据，所以就不存在竞争写数据的问题，读取速度和堆上的内存几乎没差别。 总结优点: 启动速度快，数据加载时间几乎为零。 可以解决多进程时加载重复的数据复本，从而节省内存。 缺点: 需要将数据提前放到tmpfs下。 程序退出时也不能释放内存，需要手动释放。 可能需要重新组织数据结构。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Centos下普通用户安装软件包]]></title>
      <url>%2F2017%2F07%2F10%2Fyumdownloader%2F</url>
      <content type="text"><![CDATA[在centos下，普通用户（没有root权限）安装软件的方法。 yum资源或rpm包以安装ag为例1234cd $HOME/localyumdownloader pcre-devel xz-devel the_silver_searcher rpm2cpio * | cpio -divm 源码安装123./configure --prefix=$HOME/local/makemake install 所有程序都安装到了$HOME/local/usr/目录下。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机械硬盘写入性能分析]]></title>
      <url>%2F2017%2F04%2F24%2Fhard-disk-io%2F</url>
      <content type="text"><![CDATA[现在SSD越来越普遍了，貌似现在写这个有点晚了。但是，在一些大批量写入的场景下，机械硬盘的性价比还是比较突出的。或许有一天，机械硬盘会和软盘一样被遗弃，成为历史。 机械硬盘工作原理物理结构 特性在老式的机械硬盘中，每个磁道上的扇区数相同，也就是内侧（靠近转轴）磁道上的扇区较短（密集），而外侧磁道上的扇区较长（稀疏）。这样的优点是寻址（seek）时方便，缺点时浪费空间，因为外侧磁道上可以存放更多的扇区。所以，在新式的机械硬盘中，外侧磁道上的扇区数比内侧的多。也就使得外侧磁道上读写速度大于内侧磁道。 写入性能 磁盘寻道 系统调用 内存拷贝 队列深度 BLOCK SIZE CHACHE 文件系统 Linux系统分用户空间和内核空间，一次写入操作需要把用户空间的数据通过系统调用拷贝到内核空间，再由内核调度写入磁盘。一般系统调用和内存拷贝都需要消耗较多的CPU时间。 IO模型阻塞 I/O 典型的阻塞式I/O就是直接通过write系统调用写数据。 非阻塞 I/O 非阻塞式I/O和阻塞式I/O的区别就是，非阻塞式I/O的请求会立即返回，而不必等待写入操作完成再返回。 同步 I/O异步 I/O 在Linux系统上有POSIX AIO和libaio两种异步I/O方式。POSIX AIO是一个在多个线程中执行正常阻塞I / O的用户级实现,因此给出了I / O是异步的错觉。Libaio是异步I / O操作的内核支持，其中io请求实际上在内核中排队，根据您拥有的磁盘调度程序排序, (使用TCQ或NCQ)作为异步操作转发(以某种最佳顺序希望)到实际磁盘。所以从性能的角度考虑，libaio更好一些。 写入方式fwrite更加通用的方式，通过在用户空间准备缓冲区，减少系统调用。这种做法一般情况下都会有不错的性能表现。但在高速写入的场景下CPU会成为瓶颈，因为多做了一次内存拷贝。 mmap将用户空间和内核空间做映射，以减少内存拷贝。而且特别适合随机读写。 DIO绕过内核缓冲区，直接写入磁盘的方式。这是一把双刃剑，使用起来比较麻烦，而且处理不当的话反而会更慢。 AIO配合DIO可以达到最大性能。 测试与监控工具iostat比较专业的系统I/O观测工具。排队论 iotop类似于top命令，方便观测实时I/O速度。 dd简单的写入性能测试工具。 fio可以测试硬盘的极限性能。 极限写入性能使用DIO + AIO + 多线程的方式可以达到极限性能。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git 简洁提交——合并多个commit]]></title>
      <url>%2F2017%2F04%2F10%2Fgit-squash%2F</url>
      <content type="text"><![CDATA[本地开发，服务器上编译、运行。 多台电脑间同步代码 不放心本地，为了备份经常push到代码服务器上。 因为以上等原因，我需要经常执行git commit，这就导致git的历史中包含很多无效的提交。简洁的git log和工整的代码同样重要，所以我需要合并多个commit。 简洁提交1234git checkout mastergit merge --squash featuregit commitgit push squash命令可以将整个feature分支压缩为master分支上的一个commit。 下面这条命令也可以达到类似的效果：1git merge --no-ff --no-commit 但还是有一点细微的差别，请参考这里。 修改提交历史1git rebase -i HEAD~5 -i, –interactive表示使用“交互式”的方法修改。这个命令会列出最近5个commit。大致如下： 123456789101112131415161718192021222324pick 6e53cd0 updatepick 446e6ce updatepick b1ec2c4 updatepick 366dfac updatepick 04bf27b for clear script# Rebase 574d47f..04bf27b onto 574d47f (5 command(s))## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 将pick改squash或fixup就可以将对应的commit合并到前一个commit中。区别是squash会保留commit message而fixup不会。 12345pick 6e53cd0 updatef 446e6ce updatef b1ec2c4 updatef 366dfac updatepick 04bf27b for clear script 保存退出后就会生效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一个程序员的Mac环境配置]]></title>
      <url>%2F2016%2F05%2F10%2Fmac-setup%2F</url>
      <content type="text"><![CDATA[第一篇博客，就从环境配置开始写起吧。大学时靠父母有了人生第一台笔记本，配置还不如现在的手机，但足以满足我对电脑的好奇。从XP开始，到Ubuntu，再到现在的Mac。Mac不仅“秀外”而且“慧中”。能让我在写一天代码之后感到身心愉悦。 翻墙我现在用的是轻云，用起来很舒服，但是就快停止服务了。请诸位各显神通，不过还是推荐付费的方式，它会为你节省很多时间。时间就是金钱。 推荐软件HomeBrewHomeBrew 是macOS 不可或缺的套件管理器。类似与yum、apt-get等。 iTerm2iTerm2 is a terminal emulator for macOS that does amazing things.macOS上最好的终端了。 “Oh My ZSH!”“Oh My ZSH!” Your terminal never felt this good before.私人使用时可以用zsh替代bash Dropbox我私人的Mac需要和公司的Mac同步配置文件等。以前都用github保存配置文件，但每次都要push和pull，好烦。用了Dropbox后，感觉两台电脑可以无缝切换，自动同步文件。 spacemacs传言“vim是编辑器之神，emacs是神的编辑器”。而spacemacs这是emacs之上的vim，集合了二者的优点。 之前用vim，是vim让我放弃了eclipse。但是vim用久了感觉有些焦躁，插件装多了会很慢。我现在用spacemacs，用两个词形容就是行云流水，思行合一。不是说vim不好，spacemacs也是吸纳了vim的优点。 tmuxtmux is a terminal multiplexer. 我做服务端开发，线上线下服务器，每天同时活跃的ssh登录有几十个。tmux可以让我快速的在窗口之间跳跃（一个iTerm2窗口打开9个tab，每个tab中的tmux又可以打开10个tmux的tab，90个tab间切换的时间复杂度为O(1)，足够满足我的需求了）。而且可以保持登录的session。白天用公司的Mac工作，晚上到家，打开自己的Mac可以继续服务器上的session工作。节省了很多时间，而且让我更专注于工作内容，让人心情愉悦。 AlfredAlfred is an award-winning app for Mac OS X which boosts your efficiency with hotkeys, keywords, text expansion and more. Search your Mac and the web, and be more productive with custom actions to control your Mac. 通过指令快速的在程序之间切换。现在macOS自带的Spotlight也不错。 VirtualBox虚拟机没什么好的了。macOS虽然是类Unix内核，但还是和Linux有很大区别的。装虚拟机就为了做开发或者实验环境。虚拟机上配置双网卡，一个用来访问外网，一个用来和macOS通信。开启ssh服务，共享文件等设置，物理机和虚拟机傻傻分不清楚，有事我真的觉得我的Mac可以做Linux开发。 gitgit不只可以管理代码，也可以管理文档，配置文件等。新手推荐廖雪峰的git教程。 使用习惯 Mac的键盘和触摸板要比外接的键盘鼠标更高效。 尽量使用快捷键。 后台可以跑很多进程，但要尽量隐藏不关心的内容，以免分散注意力和精力。 重复性的工作可以考虑写脚本来完成。 KISS原则：Keep It Simple, Stupid。]]></content>
    </entry>

    
  
  
</search>
